{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01287714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8403a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U awscli sagemaker boto3 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab16d2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "SageMaker Version: 2.208.0\n",
      "Boto3 Version: 1.34.44\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import sys\n",
    "\n",
    "print(f\"SageMaker Version: {sagemaker.__version__}\")\n",
    "print(f\"Boto3 Version: {boto3.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b6c672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from time import gmtime, strftime, sleep\n",
    "from uuid import uuid4\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82f654e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define region, bucket\n",
    "session = sagemaker.Session()\n",
    "region = boto3.Session().region_name\n",
    "bucket = session.default_bucket()\n",
    "# use the below for default SageMaker execution role else replace with your own IAM Role ARN\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "prefix = \"autopilot/bankadditional\"\n",
    "\n",
    "today = datetime.now().strftime(\"%d%b%Y\")\n",
    "timestamp_suffix = f\"{str(uuid4())[:6]}-{today}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e9f90b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sagemaker client object to invoke Sagemaker services\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c137648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket: s3://sagemaker-us-west-2-992382660999/autopilot/bankadditional\n",
      "Region: us-west-2\n",
      "Role: arn:aws:iam::992382660999:role/service-role/AmazonSageMaker-ExecutionRole-20240218T010479\n",
      "Job and model prefix string: bankmrkt\n",
      "suffix string: ffb634-17Feb2024\n"
     ]
    }
   ],
   "source": [
    "# Set prefix for AutoML jobnames.\n",
    "automl_job_prefix = \"bankmrkt\" \n",
    "model_prefix = automl_job_prefix\n",
    "\n",
    "print(f\"Bucket: s3://{bucket}/{prefix}\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Role: {role}\")\n",
    "print(f\"Job and model prefix string: {automl_job_prefix}\")\n",
    "print(f\"suffix string: {timestamp_suffix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5af0dc0",
   "metadata": {},
   "source": [
    "Download dataset from sagemaker-example-files-prod-{region} s3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9137f8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading bank-additional-full.csv...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "s3uri = f\"s3://sagemaker-example-files-prod-{region}/datasets/tabular/uci_bank_marketing/bank-additional-full.csv\"\n",
    "\n",
    "if not os.path.exists('data/bank-additional/bank-additional-full.csv'):\n",
    "    print(\"Downloading bank-additional-full.csv...\")\n",
    "    !mkdir -p data/bank-additional\n",
    "    S3Downloader.download(s3_uri=s3uri, local_path=\"data/bank-additional\", sagemaker_session=session)\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    print(\"Skipping download..dataset exists at ./data/bank-additional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25077708",
   "metadata": {},
   "source": [
    "**Visualize dataset**\n",
    "\n",
    "*The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y).*\n",
    "\n",
    "Problem Type: Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e5c505e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>...</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>73</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41184</th>\n",
       "      <td>46</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>56</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41186</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41187</th>\n",
       "      <td>74</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41188 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          job  marital            education  default  ...  \\\n",
       "0       56    housemaid  married             basic.4y       no  ...   \n",
       "1       57     services  married          high.school  unknown  ...   \n",
       "2       37     services  married          high.school       no  ...   \n",
       "3       40       admin.  married             basic.6y       no  ...   \n",
       "4       56     services  married          high.school       no  ...   \n",
       "...    ...          ...      ...                  ...      ...  ...   \n",
       "41183   73      retired  married  professional.course       no  ...   \n",
       "41184   46  blue-collar  married  professional.course       no  ...   \n",
       "41185   56      retired  married    university.degree       no  ...   \n",
       "41186   44   technician  married  professional.course       no  ...   \n",
       "41187   74      retired  married  professional.course       no  ...   \n",
       "\n",
       "      cons.price.idx cons.conf.idx euribor3m nr.employed    y  \n",
       "0             93.994         -36.4     4.857      5191.0   no  \n",
       "1             93.994         -36.4     4.857      5191.0   no  \n",
       "2             93.994         -36.4     4.857      5191.0   no  \n",
       "3             93.994         -36.4     4.857      5191.0   no  \n",
       "4             93.994         -36.4     4.857      5191.0   no  \n",
       "...              ...           ...       ...         ...  ...  \n",
       "41183         94.767         -50.8     1.028      4963.6  yes  \n",
       "41184         94.767         -50.8     1.028      4963.6   no  \n",
       "41185         94.767         -50.8     1.028      4963.6   no  \n",
       "41186         94.767         -50.8     1.028      4963.6  yes  \n",
       "41187         94.767         -50.8     1.028      4963.6   no  \n",
       "\n",
       "[41188 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(\"./data/bank-additional/bank-additional-full.csv\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 10)  # View all of the columns\n",
    "df_data  # show first 5 and last 5 rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d93fb48",
   "metadata": {},
   "source": [
    "**Uploading dataset to S3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3690bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this flag to False for subsequent runs of this notebook\n",
    "upload_dataset = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f2c3b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading data to s3...\n",
      "Data uploaded to : \n",
      " s3://sagemaker-us-west-2-992382660999/autopilot/bankadditional/raw/bank-additional-full.csv\n"
     ]
    }
   ],
   "source": [
    "DATA_FILE = \"data/bank-additional/bank-additional-full.csv\"\n",
    "\n",
    "if upload_dataset:\n",
    "    print(f\"Uploading data to s3...\")\n",
    "    dataset_s3uri = session.upload_data(DATA_FILE, key_prefix=f\"{prefix}/raw\")\n",
    "    print(f\"Data uploaded to : \\n {dataset_s3uri}\")\n",
    "else:\n",
    "    dataset_s3uri = f\"s3://{bucket}/{prefix}/raw/bank-additional-full.csv\"\n",
    "    print(f\"Skipping upload .. dataset is under: {dataset_s3uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b26418",
   "metadata": {},
   "source": [
    "**Launching Autopilot jobs in ENSEMBLING and HPO modes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a77b8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autopilot job params\n",
    "target_column = \"y\"\n",
    "training_mode = \"ENSEMBLING\"\n",
    "\n",
    "# Optional Parameters\n",
    "problem_type = \"BinaryClassification\"\n",
    "objective_metric = \"F1\"\n",
    "max_job_runtime_seconds = 3600\n",
    "max_runtime_per_job_seconds = 1200\n",
    "max_candidates = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2550c8d4",
   "metadata": {},
   "source": [
    "**Defining Autopilot job config values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c9d1007",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_job_config = {\n",
    "    \"CompletionCriteria\": {\n",
    "        \"MaxRuntimePerTrainingJobInSeconds\": max_runtime_per_job_seconds,\n",
    "        \"MaxAutoMLJobRuntimeInSeconds\": max_job_runtime_seconds,\n",
    "    },\n",
    "    \"Mode\": training_mode,\n",
    "}\n",
    "\n",
    "automl_job_objective = {\"MetricName\": objective_metric}\n",
    "\n",
    "input_data_config = [\n",
    "    {\n",
    "        \"DataSource\": {\"S3DataSource\": {\"S3DataType\": \"S3Prefix\", \"S3Uri\": dataset_s3uri}},\n",
    "        \"TargetAttributeName\": target_column,\n",
    "    }\n",
    "]\n",
    "\n",
    "output_data_config = {\"S3OutputPath\": f\"s3://{bucket}/{prefix}/output\"}\n",
    "\n",
    "# Optional: Define a Tag\n",
    "tags_config = [{\"Key\": \"Project\", \"Value\": \"Autopilot-serverless\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbca789",
   "metadata": {},
   "source": [
    "**Launch Autopilot job with training mode set to ENSEMBLING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6401ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching AutoMLJob → bankmrkt-ENS-ffb634-17Feb2024 with mode set to ENSEMBLING\n",
      "{'AutoMLJobArn': 'arn:aws:sagemaker:us-west-2:992382660999:automl-job/bankmrkt-ENS-ffb634-17Feb2024', 'ResponseMetadata': {'RequestId': '5844c8ab-012c-4f40-aa8b-382bb3e5f83d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '5844c8ab-012c-4f40-aa8b-382bb3e5f83d', 'content-type': 'application/x-amz-json-1.1', 'content-length': '100', 'date': 'Sat, 17 Feb 2024 20:07:03 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ens_automl_job_name = f\"{model_prefix}-ENS-{timestamp_suffix}\"\n",
    "    print(f\"Launching AutoMLJob → {ens_automl_job_name} with mode set to {training_mode}\")\n",
    "    response = sm_client.create_auto_ml_job(\n",
    "        AutoMLJobName=ens_automl_job_name,\n",
    "        InputDataConfig=input_data_config,\n",
    "        OutputDataConfig=output_data_config,\n",
    "        AutoMLJobConfig=automl_job_config,\n",
    "        ProblemType=problem_type,\n",
    "        AutoMLJobObjective=automl_job_objective,\n",
    "        RoleArn=role,\n",
    "        Tags=tags_config,\n",
    "    )\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"Error launching ENSEMBLING Autopilot Job: {ens_automl_job_name}\")\n",
    "    print(f\"{e}\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e782e818",
   "metadata": {},
   "source": [
    "**Launching Autopilot job with training mode set to HYPERPARAMETER_TUNING mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56611df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching AutoMLJob → bankmrkt-HPO-ffb634-17Feb2024 with mode set to HYPERPARAMETER_TUNING\n",
      "{'AutoMLJobArn': 'arn:aws:sagemaker:us-west-2:992382660999:automl-job/bankmrkt-HPO-ffb634-17Feb2024', 'ResponseMetadata': {'RequestId': '99b186b3-29a5-43a8-9b65-28095733e933', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '99b186b3-29a5-43a8-9b65-28095733e933', 'content-type': 'application/x-amz-json-1.1', 'content-length': '100', 'date': 'Sat, 17 Feb 2024 20:07:49 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# We use the defined job prefix to construct model name(s) and later to construct endpoint config and endpoint names.\n",
    "try:\n",
    "    training_mode = \"HYPERPARAMETER_TUNING\"\n",
    "    automl_job_config[\"Mode\"] = training_mode\n",
    "    automl_job_config[\"CompletionCriteria\"][\"MaxCandidates\"] = 15\n",
    "    hpo_automl_job_name = f\"{model_prefix}-HPO-{timestamp_suffix}\"\n",
    "    print(f\"Launching AutoMLJob → {hpo_automl_job_name} with mode set to {training_mode}\")\n",
    "    response = sm_client.create_auto_ml_job(\n",
    "        AutoMLJobName=hpo_automl_job_name,\n",
    "        InputDataConfig=input_data_config,\n",
    "        OutputDataConfig=output_data_config,\n",
    "        AutoMLJobConfig=automl_job_config,\n",
    "        ProblemType=problem_type,\n",
    "        AutoMLJobObjective=automl_job_objective,\n",
    "        RoleArn=role,\n",
    "        Tags=tags_config,\n",
    "    )\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"Error launching HPO Autopilot Job: {hpo_automl_job_name}\")\n",
    "    print(f\"{e}\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b0ab56",
   "metadata": {},
   "source": [
    "**Monitoring AutoML job completion status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e24dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_status(sm_client, job_name):\n",
    "    resp = sm_client.describe_auto_ml_job(AutoMLJobName=job_name)\n",
    "    p_status = resp[\"AutoMLJobStatus\"]\n",
    "    s_status = resp[\"AutoMLJobSecondaryStatus\"]\n",
    "    desc = f\"{job_name}: {p_status} | {s_status} ...\"\n",
    "    return (p_status, desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a39d5e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n",
      "bankmrkt-ENS-ffb634-17Feb2024: InProgress | TrainingModels ...\n"
     ]
    }
   ],
   "source": [
    "# monitor job status launched in ensembling mode\n",
    "(p_status, desc) = get_job_status(sm_client, ens_automl_job_name)\n",
    "\n",
    "while p_status not in (\"Completed\", \"Failed\"):\n",
    "    (p_status, desc) = get_job_status(sm_client, ens_automl_job_name)\n",
    "    if p_status not in (\"Completed\", \"Failed\"):\n",
    "        print(desc)\n",
    "        sleep(60)\n",
    "        continue\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "44306c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autopilot_model(sm_client, model_name, role, model_container, index):\n",
    "    try:\n",
    "        transform_mode = model_container[\"Environment\"][\"AUTOML_TRANSFORM_MODE\"]\n",
    "        if transform_mode:\n",
    "            model_name = f\"{model_name}-datamodel-{index}\"\n",
    "    except:\n",
    "        model_name = f\"{model_name}-Inf-{index}\"\n",
    "\n",
    "    if len(model_name) <= 63:\n",
    "        print(f\"Creating Model {index}: {model_name} ...\")\n",
    "        model_response = sm_client.create_model(\n",
    "            ModelName=model_name, ExecutionRoleArn=role, Containers=[model_container]\n",
    "        )\n",
    "        status_code = model_response[\"ResponseMetadata\"][\"HTTPStatusCode\"]\n",
    "        model_arn = model_response[\"ModelArn\"]\n",
    "        return (status_code, model_arn)\n",
    "    else:\n",
    "        print(f\"Model Name: {model_name} length exceeds max. allowed chars : 63\")\n",
    "        raise ValueError(\"Model name cannot exceed 63 chars.\")\n",
    "\n",
    "\n",
    "def create_serverless_endpoint_config(\n",
    "    sm_client, endpoint_config_name, model_name, memory: int = 2048, max_concurrency: int = 20\n",
    "):\n",
    "    if len(endpoint_config_name) <= 63:\n",
    "        print(f\"Creating Endpoint Config: {endpoint_config_name} ...\")\n",
    "        try:\n",
    "            epc_response = sm_client.create_endpoint_config(\n",
    "                EndpointConfigName=endpoint_config_name,\n",
    "                ProductionVariants=[\n",
    "                    {\n",
    "                        \"ModelName\": model_name,\n",
    "                        \"VariantName\": \"AllTraffic\",\n",
    "                        \"ServerlessConfig\": {\n",
    "                            \"MemorySizeInMB\": memory,\n",
    "                            \"MaxConcurrency\": max_concurrency,\n",
    "                        },\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "            status_code = epc_response[\"ResponseMetadata\"][\"HTTPStatusCode\"]\n",
    "            epc_arn = epc_response[\"EndpointConfigArn\"]\n",
    "            return (status_code, epc_arn)\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating EndpointConfig: {endpoint_config_name}\")\n",
    "            print(f\"{e}\")\n",
    "    else:\n",
    "        print(f\"EndpointConfig name exceeds allowed 63 char limit\")\n",
    "        raise ValueError(\"EndpointConfig name cannot exceed 63 chars.\")\n",
    "\n",
    "\n",
    "def create_serverless_endpoint(sm_client, endpoint_name, endpoint_config_name):\n",
    "    if len(endpoint_name) <= 63:\n",
    "        print(f\"Creating Serverless Endpoint: {endpoint_name} ...\")\n",
    "        try:\n",
    "            ep_response = sm_client.create_endpoint(\n",
    "                EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    "            )\n",
    "            status_code = ep_response[\"ResponseMetadata\"][\"HTTPStatusCode\"]\n",
    "            return status_code\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating Endpoint: {endpoint_name}\")\n",
    "            print(f\"{e}\")\n",
    "    else:\n",
    "        print(f\"Endpoint name exceeds allowed 63 char limit\")\n",
    "        raise ValueError(\"Endpoint name cannot exceed 63 chars.\")\n",
    "\n",
    "\n",
    "def get_s3_objsize_in_MB(bucket, key):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    resp = s3.head_object(Bucket=bucket, Key=key)[\"ContentLength\"]\n",
    "    size = round(resp / (1024 * 1024))\n",
    "    if size < 1:\n",
    "        print(f\"Model Size: ~ {round(resp / 1024)} KB\")\n",
    "    else:\n",
    "        print(f\"Model Size: ~ {size} MB\")\n",
    "\n",
    "    return size\n",
    "\n",
    "\n",
    "def set_serverless_endpoint_memory(model_size: int):\n",
    "    if model_size <= 1024:\n",
    "        return 1024\n",
    "    elif model_size > 1024 and model_size <= 2048:\n",
    "        return 2048\n",
    "    elif model_size > 2048 and model_size <= 3072:\n",
    "        return 3072\n",
    "    elif model_size > 3072 and model_size <= 4096:\n",
    "        return 4096\n",
    "    elif model_size > 4096 and model_size <= 5120:\n",
    "        return 5120\n",
    "    elif model_size > 5120 and model_size <= 6144:\n",
    "        return 6144\n",
    "    elif model_size > 6144:\n",
    "        raise ValueError(\"Model size is greater than 6GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e4cf1546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Container for AutoML job: bankmrkt-ENS-ffb634-17Feb2024\n",
      "{'Image': '763104351884.dkr.ecr.us-west-2.amazonaws.com/autogluon-inference:0.4.3-cpu-py38-ubuntu20.04', 'ModelDataUrl': 's3://sagemaker-us-west-2-992382660999/autopilot/bankadditional/output/bankmrkt-ENS-ffb634-17Feb2024/sagemaker-automl-candidates/model/WeightedEnsemble-L2-FULL-t3/model.tar.gz', 'Environment': {'MODEL_NAME': 'WeightedEnsemble-L2-FULL', 'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT': 'text/csv', 'SAGEMAKER_INFERENCE_OUTPUT': 'predicted_label', 'SAGEMAKER_INFERENCE_SUPPORTED': 'predicted_label,probability,probabilities,labels', 'SAGEMAKER_PROGRAM': 'tabular_serve.py', 'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code'}}\n",
      "Model Size: ~ 3 MB\n",
      "Ensemble Model Size: ~ 3MB\n"
     ]
    }
   ],
   "source": [
    "response = sm_client.describe_auto_ml_job(AutoMLJobName=ens_automl_job_name)\n",
    "inference_container = response[\"BestCandidate\"][\"InferenceContainers\"][0]\n",
    "print(f\"Inference Container for AutoML job: {ens_automl_job_name}\")\n",
    "print(inference_container)\n",
    "\n",
    "# Verify generated model size before creating endpoint config.\n",
    "# Extract s3 Key from ModelDataUrl\n",
    "model_dataurl_key = inference_container[\"ModelDataUrl\"].split(f\"{bucket}\")[1][1:]\n",
    "ens_model_size = get_s3_objsize_in_MB(bucket, model_dataurl_key)\n",
    "print(f\"Ensemble Model Size: ~ {ens_model_size}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c142f746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model 0: bankmrkt-ENS-ffb634-17Feb2024-Inf-0 ...\n",
      "Creating Endpoint Config: epc-bankmrkt-ens-ffb634-17feb2024-inf-0 ...\n",
      "Creating Serverless Endpoint: ep-bankmrkt-ens-ffb634-17feb2024-inf-0 ...\n"
     ]
    }
   ],
   "source": [
    "models = list()\n",
    "# create model\n",
    "(status, model_arn) = create_autopilot_model(\n",
    "    sm_client, ens_automl_job_name, role, inference_container, 0\n",
    ")\n",
    "model_name = model_arn.split(\"/\")[1]\n",
    "models.append(model_name)\n",
    "\n",
    "endpoint_configs = list()\n",
    "endpoint_config_name = f\"epc-{model_name}\"\n",
    "memory = 3072\n",
    "# create endpoint config\n",
    "(status, epc_arn) = create_serverless_endpoint_config(\n",
    "    sm_client, endpoint_config_name, model_name, memory=memory, max_concurrency=10\n",
    ")\n",
    "endpoint_configs.append(endpoint_config_name)\n",
    "\n",
    "endpoints = list()\n",
    "endpoint_name = endpoint_config_name.replace(\"epc-\", \"ep-\")\n",
    "# create serverless endpoint\n",
    "create_serverless_endpoint(sm_client, endpoint_name, endpoint_config_name)\n",
    "endpoints.append(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "84dc60fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_endpoint_status(sm_client, endpoint_name):\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    desc = f\"{endpoint_name} | {status} ...\"\n",
    "    return (status, desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ecaab1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-bankmrkt-ens-ffb634-17feb2024-inf-0 | InService ...\n"
     ]
    }
   ],
   "source": [
    "# monitor endpoint status\n",
    "(status, desc) = get_endpoint_status(sm_client, endpoint_name)\n",
    "print(desc)\n",
    "while status not in (\"InService\", \"Failed\"):\n",
    "    (status, desc) = get_endpoint_status(sm_client, endpoint_name)\n",
    "    if status not in (\"InService\", \"Failed\"):\n",
    "        print(desc)\n",
    "        sleep(60)\n",
    "        continue\n",
    "    else:\n",
    "        print(desc)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b2845f",
   "metadata": {},
   "source": [
    "**Sending Inference request to serverless endpoint with ENSEMBLE model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3c0d56b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking endpoint: ep-bankmrkt-ens-ffb634-17feb2024-inf-0 with payload .. \n",
      "\n",
      "51,technician,married,professional.course,no,yes,no,cellular,apr,thu,687,1,0,1,success,-1.8,93.075,-47.1,1.365,5099.1\n",
      "Predicted Label: yes\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "\n",
    "endpoint = endpoints[0]\n",
    "\n",
    "payload = \"51,technician,married,professional.course,no,yes,no,cellular,apr,thu,687,1,0,1,success,-1.8,93.075,-47.1,1.365,5099.1\"\n",
    "# payload = \"42,services,married,professional.course,no,yes,no,telephone,may,thu,813,1,999,0,nonexistent,1.1,93.994,-36.4,4.855,5191.0\"\n",
    "# payload = \"37,services,married,high.school,no,yes,no,telephone,may,mon,226,1,999,0,nonexistent,1.1,93.994,-36.4,4.857,5191.0\"\n",
    "# payload = \"55,admin.,married,high.school,no,no,no,telephone,may,thu,94,1,999,0,nonexistent,1.1,93.994,-36.4,4.855,5191.0\"\n",
    "# payload = \"34,blue-collar,married,basic.4y,no,no,no,telephone,may,tue,800,4,999,0,nonexistent,1.1,93.994,-36.4,4.857,5191.0\"\n",
    "\n",
    "try:\n",
    "    print(f\"Invoking endpoint: {endpoint} with payload .. \\n\")\n",
    "    print(payload)\n",
    "    predictor = Predictor(\n",
    "        endpoint_name=endpoint,\n",
    "        sagmaker_session=session,\n",
    "        serializer=CSVSerializer(),\n",
    "        deserializer=CSVDeserializer(),\n",
    "    )\n",
    "    prediction = predictor.predict(payload)\n",
    "    print(f\"Predicted Label: {prediction[0][0]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error invoking Endpoint: {endpoint}\")\n",
    "    print(f\"{e}\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55dd994",
   "metadata": {},
   "source": [
    "**Cleanup (ensemble endpoint)**\n",
    "\n",
    "Deleting endpoint, endpoint config and model in that order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b579f11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting endpoint : ep-bankmrkt-ens-ffb634-17feb2024-inf-0\n",
      "Deleting EndpointConfig : epc-bankmrkt-ens-ffb634-17feb2024-inf-0\n",
      "Deleting Model : bankmrkt-ens-ffb634-17feb2024-inf-0\n"
     ]
    }
   ],
   "source": [
    "epc_name = endpoint.replace(\"ep-\", \"epc-\")\n",
    "model_name = endpoint.replace(\"ep-\", \"\")\n",
    "\n",
    "print(f\"Deleting endpoint : {endpoint}\")\n",
    "try:\n",
    "    sm_client.delete_endpoint(EndpointName=endpoint)\n",
    "except Exception as e:\n",
    "    print(f\"{e}\")\n",
    "    pass\n",
    "\n",
    "print(f\"Deleting EndpointConfig : {epc_name}\")\n",
    "try:\n",
    "    sm_client.delete_endpoint_config(EndpointConfigName=epc_name)\n",
    "except Exception as e:\n",
    "    print(f\"{e}\")\n",
    "    pass\n",
    "\n",
    "print(f\"Deleting Model : {model_name}\")\n",
    "try:\n",
    "    sm_client.delete_model(ModelName=model_name)\n",
    "except Exception as e:\n",
    "    print(f\"{e}\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971be8db",
   "metadata": {},
   "source": [
    "***Deploying HPO models to serverless endpoints***\n",
    "\n",
    "Autopilot in HYPERPARAMETER_TUNING mode generates 3 inference containers for binary classification problem types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6f39a0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bankmrkt-HPO-ffb634-17Feb2024: Completed | Completed ...\n"
     ]
    }
   ],
   "source": [
    "# monitor job status launched in hpo mode\n",
    "(p_status, desc) = get_job_status(sm_client, hpo_automl_job_name)\n",
    "print(desc)\n",
    "while p_status not in (\"Completed\", \"Failed\"):\n",
    "    (p_status, desc) = get_job_status(sm_client, hpo_automl_job_name)\n",
    "    if p_status not in (\"Completed\", \"Failed\"):\n",
    "        print(desc)\n",
    "        sleep(60)\n",
    "        continue\n",
    "    else:\n",
    "        print(desc)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "97d47877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Containers for AutoML job: bankmrkt-HPO-ffb634-17Feb2024\n",
      "[{'Image': '246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-sklearn-automl:2.5-1-cpu-py3', 'ModelDataUrl': 's3://sagemaker-us-west-2-992382660999/autopilot/bankadditional/output/bankmrkt-HPO-ffb634-17Feb2024/data-processor-models/bankmrkt-HPO-ffb634-17Feb2024-dpp4-1-54efc9be7a8f479cb1c3c6626f/output/model.tar.gz', 'Environment': {'AUTOML_SPARSE_ENCODE_RECORDIO_PROTOBUF': '1', 'AUTOML_TRANSFORM_MODE': 'feature-transform', 'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT': 'application/x-recordio-protobuf', 'SAGEMAKER_PROGRAM': 'sagemaker_serve', 'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code'}}, {'Image': '246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-xgboost:1.3-1-cpu-py3', 'ModelDataUrl': 's3://sagemaker-us-west-2-992382660999/autopilot/bankadditional/output/bankmrkt-HPO-ffb634-17Feb2024/tuning/bankmrkt-H-dpp4-xgb/bankmrkt-HPO-ffb634-17Feb2024nuh-012-c2a73931/output/model.tar.gz', 'Environment': {'MAX_CONTENT_LENGTH': '20971520', 'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT': 'text/csv', 'SAGEMAKER_INFERENCE_OUTPUT': 'predicted_label', 'SAGEMAKER_INFERENCE_SUPPORTED': 'predicted_label,probability,probabilities'}}, {'Image': '246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-sklearn-automl:2.5-1-cpu-py3', 'ModelDataUrl': 's3://sagemaker-us-west-2-992382660999/autopilot/bankadditional/output/bankmrkt-HPO-ffb634-17Feb2024/data-processor-models/bankmrkt-HPO-ffb634-17Feb2024-dpp4-1-54efc9be7a8f479cb1c3c6626f/output/model.tar.gz', 'Environment': {'AUTOML_TRANSFORM_MODE': 'inverse-label-transform', 'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT': 'text/csv', 'SAGEMAKER_INFERENCE_INPUT': 'predicted_label', 'SAGEMAKER_INFERENCE_OUTPUT': 'predicted_label', 'SAGEMAKER_INFERENCE_SUPPORTED': 'predicted_label,probability,labels,probabilities', 'SAGEMAKER_PROGRAM': 'sagemaker_serve', 'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code'}}]\n"
     ]
    }
   ],
   "source": [
    "job_response = sm_client.describe_auto_ml_job(AutoMLJobName=hpo_automl_job_name)\n",
    "inference_containers = job_response[\"BestCandidate\"][\"InferenceContainers\"]\n",
    "print(f\"Inference Containers for AutoML job: {hpo_automl_job_name}\")\n",
    "print(inference_containers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "eeea4c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating generated model_0 size\n",
      "Model Size: ~ 13 KB\n",
      "calculating generated model_1 size\n",
      "Model Size: ~ 1 MB\n",
      "calculating generated model_2 size\n",
      "Model Size: ~ 13 KB\n"
     ]
    }
   ],
   "source": [
    "for idx, container in enumerate(inference_containers):\n",
    "    print(f\"calculating generated model_{idx} size\")\n",
    "    # Extract s3 Key from ModelDataUrl\n",
    "    model_dataurl_key = container[\"ModelDataUrl\"].split(f\"{bucket}\")[1][1:]\n",
    "    # print(model_dataurl_key)\n",
    "    model_size = get_s3_objsize_in_MB(bucket, model_dataurl_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7f908257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model 0: bankmrkt-HPO-ffb634-17Feb2024-datamodel-0 ...\n",
      "\tcreated model: bankmrkt-hpo-ffb634-17feb2024-datamodel-0...\n",
      "Creating Endpoint Config: epc-bankmrkt-hpo-ffb634-17feb2024-datamodel-0 ...\n",
      "\tcreated epc: epc-bankmrkt-hpo-ffb634-17feb2024-datamodel-0\n",
      "Creating Serverless Endpoint: ep-bankmrkt-hpo-ffb634-17feb2024-datamodel-0 ...\n",
      "\tcreated ep: ep-bankmrkt-hpo-ffb634-17feb2024-datamodel-0\n",
      "Creating Model 1: bankmrkt-HPO-ffb634-17Feb2024-Inf-1 ...\n",
      "\tcreated model: bankmrkt-hpo-ffb634-17feb2024-inf-1...\n",
      "Creating Endpoint Config: epc-bankmrkt-hpo-ffb634-17feb2024-inf-1 ...\n",
      "\tcreated epc: epc-bankmrkt-hpo-ffb634-17feb2024-inf-1\n",
      "Creating Serverless Endpoint: ep-bankmrkt-hpo-ffb634-17feb2024-inf-1 ...\n",
      "Error creating Endpoint: ep-bankmrkt-hpo-ffb634-17feb2024-inf-1\n",
      "An error occurred (ResourceLimitExceeded) when calling the CreateEndpoint operation: The account-level service limit 'Maximum total concurrency that can be allocated across all serverless endpoints' is 10 Number, with current utilization of 10 Number and a request delta of 10 Number. Please use AWS Service Quotas to request an increase for this quota. If AWS Service Quotas is not available, contact AWS support to request an increase for this quota.\n",
      "\tcreated ep: ep-bankmrkt-hpo-ffb634-17feb2024-inf-1\n",
      "Creating Model 2: bankmrkt-HPO-ffb634-17Feb2024-datamodel-2 ...\n",
      "\tcreated model: bankmrkt-hpo-ffb634-17feb2024-datamodel-2...\n",
      "Creating Endpoint Config: epc-bankmrkt-hpo-ffb634-17feb2024-datamodel-2 ...\n",
      "\tcreated epc: epc-bankmrkt-hpo-ffb634-17feb2024-datamodel-2\n",
      "Creating Serverless Endpoint: ep-bankmrkt-hpo-ffb634-17feb2024-datamodel-2 ...\n",
      "Error creating Endpoint: ep-bankmrkt-hpo-ffb634-17feb2024-datamodel-2\n",
      "An error occurred (ResourceLimitExceeded) when calling the CreateEndpoint operation: The account-level service limit 'Maximum total concurrency that can be allocated across all serverless endpoints' is 10 Number, with current utilization of 10 Number and a request delta of 10 Number. Please use AWS Service Quotas to request an increase for this quota. If AWS Service Quotas is not available, contact AWS support to request an increase for this quota.\n",
      "\tcreated ep: ep-bankmrkt-hpo-ffb634-17feb2024-datamodel-2\n"
     ]
    }
   ],
   "source": [
    "models = list()\n",
    "endpoint_configs = list()\n",
    "endpoints = list()\n",
    "\n",
    "memory = 2048\n",
    "max_concurreny = 10\n",
    "\n",
    "# Create model, endpoint_config, endpoint and store them in lists for easier access\n",
    "for idx, container in enumerate(inference_containers):\n",
    "    (status, model_arn) = create_autopilot_model(\n",
    "        sm_client, hpo_automl_job_name, role, container, idx\n",
    "    )\n",
    "    model_name = model_arn.split(\"/\")[1]\n",
    "    print(f\"\\tcreated model: {model_name}...\")\n",
    "    models.append(model_name)\n",
    "\n",
    "    endpoint_config_name = f\"epc-{model_name}\"\n",
    "    endpoint_name = f\"ep-{model_name}\"\n",
    "\n",
    "    (status, epc_arn) = create_serverless_endpoint_config(\n",
    "        sm_client, endpoint_config_name, model_name, memory=memory, max_concurrency=max_concurreny\n",
    "    )\n",
    "    print(f\"\\tcreated epc: {endpoint_config_name}\")\n",
    "    endpoint_configs.append(endpoint_config_name)\n",
    "\n",
    "    res = create_serverless_endpoint(sm_client, endpoint_name, endpoint_config_name)\n",
    "    print(f\"\\tcreated ep: {endpoint_name}\")\n",
    "    endpoints.append(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cbc356b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['InService']\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from time import sleep\n",
    "\n",
    "# Initialize the boto3 SageMaker client\n",
    "sm_client = boto3.client('sagemaker', region_name='us-west-2')\n",
    "\n",
    "# Replace with your actual endpoint names\n",
    "endpoints = ['ep-bankmrkt-hpo-ffb634-17feb2024-datamodel-0']\n",
    "\n",
    "# Function to get the status of the endpoint\n",
    "def get_endpoint_status(client, endpoint_name):\n",
    "    response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    return response['EndpointStatus']\n",
    "\n",
    "# Get the initial statuses for all endpoints\n",
    "statuses = [get_endpoint_status(sm_client, ep) for ep in endpoints]\n",
    "print(statuses)\n",
    "\n",
    "# Continue looping until the endpoint is in service\n",
    "while statuses != [\"InService\"]:  # Adjust the condition based on the actual number of endpoints\n",
    "    statuses = [get_endpoint_status(sm_client, ep) for ep in endpoints]\n",
    "    print(statuses)\n",
    "    \n",
    "    # If the status is not \"InService\", wait for 60 seconds before checking again\n",
    "    if statuses != [\"InService\"]:\n",
    "        sleep(60)\n",
    "    else:\n",
    "        print(\"All endpoints are in service.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d6fc5932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload: 51,technician,married,professional.course,no,yes,no,cellular,apr,thu,687,1,0,1,success,-1.8,93.075,-47.1,1.365,5099.1\n",
      "Error invoking Endpoint: ep-bankmrkt-hpo-ffb634-17feb2024-datamodel-0 \n",
      " An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\n",
      "<title>500 Internal Server Error</title>\n",
      "<h1>Internal Server Error</h1>\n",
      "<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n",
      "\". See https://us-west-2.console.aws.amazon.com/cloudwatch/home?region=us-west-2#logEventViewer:group=/aws/sagemaker/Endpoints/ep-bankmrkt-hpo-ffb634-17feb2024-datamodel-0 in account 992382660999 for more information.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer, IdentitySerializer\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "\n",
    "# Assuming 'endpoints' is a list of your endpoint names and 'session' is a valid SageMaker session\n",
    "payload = \"51,technician,married,professional.course,no,yes,no,cellular,apr,thu,687,1,0,1,success,-1.8,93.075,-47.1,1.365,5099.1\"\n",
    "\n",
    "for idx, ep in enumerate(endpoints):\n",
    "    try:\n",
    "        print(f\"Payload: {payload}\")\n",
    "        # Check your logic for when to use IdentitySerializer vs. CSVSerializer\n",
    "        if idx == 1:\n",
    "            predictor = Predictor(\n",
    "                endpoint_name=ep,\n",
    "                sagemaker_session=session,\n",
    "                serializer=IdentitySerializer(content_type=\"application/x-recordio-protobuf\"),\n",
    "                deserializer=CSVDeserializer(),\n",
    "            )\n",
    "        else:\n",
    "            predictor = Predictor(\n",
    "                endpoint_name=ep, sagemaker_session=session, serializer=CSVSerializer(),\n",
    "                deserializer=CSVDeserializer()  # Assuming the endpoint returns CSV formatted string\n",
    "            )\n",
    "        prediction = predictor.predict(payload)\n",
    "        print(f\"Prediction for endpoint {ep}: \\n{prediction}\")\n",
    "        print(\"--\" * 20)\n",
    "    except Exception as e:\n",
    "        print(f\"Error invoking Endpoint: {ep} \\n {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc2d477",
   "metadata": {},
   "source": [
    "**Cleanup (HPO endpoints)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2e5f0d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting endpoints...\n",
      "\tDeleting ep-bankmrkt-hpo-ffb634-17feb2024-datamodel-0...\n",
      "An error occurred (ValidationException) when calling the DeleteEndpoint operation: Could not find endpoint \"ep-bankmrkt-hpo-ffb634-17feb2024-datamodel-0\".\n",
      "------------------------------\n",
      "Deleting endpoint configs...\n",
      "\tDeleting epc-bankmrkt-hpo-ffb634-17feb2024-datamodel-0 ...\n",
      "An error occurred (ValidationException) when calling the DeleteEndpointConfig operation: Could not find endpoint configuration \"epc-bankmrkt-hpo-ffb634-17feb2024-datamodel-0\".\n",
      "\tDeleting epc-bankmrkt-hpo-ffb634-17feb2024-inf-1 ...\n",
      "An error occurred (ValidationException) when calling the DeleteEndpointConfig operation: Could not find endpoint configuration \"epc-bankmrkt-hpo-ffb634-17feb2024-inf-1\".\n",
      "\tDeleting epc-bankmrkt-hpo-ffb634-17feb2024-datamodel-2 ...\n",
      "An error occurred (ValidationException) when calling the DeleteEndpointConfig operation: Could not find endpoint configuration \"epc-bankmrkt-hpo-ffb634-17feb2024-datamodel-2\".\n",
      "------------------------------\n",
      "Deleting models...\n",
      "\tDeleting bankmrkt-hpo-ffb634-17feb2024-datamodel-0...\n",
      "An error occurred (ValidationException) when calling the DeleteModel operation: Could not find model \"bankmrkt-hpo-ffb634-17feb2024-datamodel-0\".\n",
      "\tDeleting bankmrkt-hpo-ffb634-17feb2024-inf-1...\n",
      "An error occurred (ValidationException) when calling the DeleteModel operation: Could not find model \"bankmrkt-hpo-ffb634-17feb2024-inf-1\".\n",
      "\tDeleting bankmrkt-hpo-ffb634-17feb2024-datamodel-2...\n",
      "An error occurred (ValidationException) when calling the DeleteModel operation: Could not find model \"bankmrkt-hpo-ffb634-17feb2024-datamodel-2\".\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Deleting endpoints...\")\n",
    "for _, ep in enumerate(endpoints):\n",
    "    try:\n",
    "        print(f\"\\tDeleting {ep}...\")\n",
    "        sm_client.delete_endpoint(EndpointName=ep)\n",
    "    except Exception as e:\n",
    "        print(f\"{e}\")\n",
    "        continue\n",
    "print(\"--\" * 15)\n",
    "print(\"Deleting endpoint configs...\")\n",
    "for _, epc in enumerate(endpoint_configs):\n",
    "    try:\n",
    "        print(f\"\\tDeleting {epc} ...\")\n",
    "        sm_client.delete_endpoint_config(EndpointConfigName=epc)\n",
    "    except Exception as e:\n",
    "        print(f\"{e}\")\n",
    "        continue\n",
    "print(\"--\" * 15)\n",
    "print(\"Deleting models...\")\n",
    "for _, mdl in enumerate(models):\n",
    "    try:\n",
    "        print(f\"\\tDeleting {mdl}...\")\n",
    "        sm_client.delete_model(ModelName=mdl)\n",
    "    except Exception as e:\n",
    "        print(f\"{e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace37996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c6d92a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
